apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: alerts-awx
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "gp-awx-monitoring.labels" . | nindent 4 }}
spec:
  groups:
    - name: alerts-awx
      rules:
        - alert: awx_podcount
          annotations:
            description: Es muss zumindest 1 Pod da sein
            summary: AWX auf dem HUB-Cluster ist nicht erreichbar
          expr: 'absent(sum(up{job=''awx''})>=1)'
          for: 10m
          labels:
            severity: "critical"
            type: "internal"
        - alert: awx_memory_saturation
          annotations:
            summary: AWX Memory Issue
            description: |
              AWX hat in den letzten 10 Minuten durchschnittlich mehr als 150% der Memory Requests benÃ¶tigt. Es ist sehr wahrscheinlich, dass hier ein Problem besteht.
              siehe auch: https://grafana.infra.gepaplexx.com/d/a164a7f0339f99e89cea5cb47e9be617/kubernetes-compute-resources-workload?orgId=1&refresh=10s&var-datasource=default&var-cluster=&var-namespace={{ .Release.Namespace }}&var-type=deployment&var-workload=awx
          expr: |
            (sum(
                avg_over_time(container_memory_working_set_bytes{namespace="{{ .Release.Namespace }}", container!="", image!=""}[10m])
              * on(namespace,pod)
                group_left(workload, workload_type) namespace_workload_pod:kube_pod_owner:relabel{ namespace="{{ .Release.Namespace }}", workload="awx", workload_type="deployment"}
            ) by (pod)
            /sum(
                kube_pod_container_resource_requests{job="kube-state-metrics",namespace="{{ .Release.Namespace }}", resource="memory"}
              * on(namespace,pod)
                group_left(workload, workload_type) namespace_workload_pod:kube_pod_owner:relabel{namespace="{{ .Release.Namespace }}",workload="awx",workload_type="deployment"}
            ) by (pod) > 1.5
          for: 10m
          labels:
            severity: "critical"
            type: "internal"
        - alert: awx_cpu_saturation
          annotations:
            summary: AWX CPU Issue
            description: |
              AWX hat in den letzten 10 Minuten durchschnitlich mehr als 120% der requesten CPU verbraucht. Es ist sehr wahrscheinlich, dass hier ein Problem besteht.
              siehe auch: https://grafana.infra.gepaplexx.com/d/a164a7f0339f99e89cea5cb47e9be617/kubernetes-compute-resources-workload?orgId=1&refresh=10s&var-datasource=default&var-cluster=&var-namespace={{ .Release.Namespace }}&var-type=deployment&var-workload=awx
          expr: |
            (sum(
                avg_over_time(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{namespace="{{ .Release.Namespace }}"}[10m])
              * on(namespace,pod)
                group_left(workload, workload_type) namespace_workload_pod:kube_pod_owner:relabel{namespace="{{ .Release.Namespace }}", workload="awx", workload_type="deployment"}
            ) by (pod)
            /sum(
                kube_pod_container_resource_requests{job="kube-state-metrics",namespace="{{ .Release.Namespace }}", resource="cpu"}
              * on(namespace,pod)
                group_left(workload, workload_type) namespace_workload_pod:kube_pod_owner:relabel{namespace="{{ .Release.Namespace }}", workload="awx", workload_type="deployment"}
            ) by (pod)) > 1.2
          for: 10m
          labels:
            severity: "critical"
            type: "internal"


